{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T15:34:36.107050Z","iopub.status.busy":"2023-08-01T15:34:36.106687Z","iopub.status.idle":"2023-08-01T15:34:36.113062Z","shell.execute_reply":"2023-08-01T15:34:36.112151Z","shell.execute_reply.started":"2023-08-01T15:34:36.107018Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch ## Были проблемы с torch т.к мы используем ROCm вместо CUDA: проверяем, определена ли видеокарта\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os ## \"оптимизированная\" загрузка данных \n","import pandas as pd\n","directory = '/home/maxem/Downloads/aclImdb/train/pos'  # Replace with the actual directory path\n","\n","data = []\n","for filename in os.listdir(directory):\n","    if filename.endswith('.txt'):\n","        filepath = os.path.join(directory, filename)\n","        with open(filepath, 'r') as file:\n","            review = file.read()\n","            id, rating = filename.split('_')\n","            rating = int(rating.split(\".\")[0])\n","            data.append({'id': id, 'review': review, 'rating': rating, 'outcome': 1})\n","\n","df_pos = pd.DataFrame(data)\n","\n","\n","directory = '/home/maxem/Downloads/aclImdb/train/neg'  # Replace with the actual directory path\n","\n","data = []\n","for filename in os.listdir(directory):\n","    if filename.endswith('.txt'):\n","        filepath = os.path.join(directory, filename)\n","        with open(filepath, 'r') as file:\n","            review = file.read()\n","            id, rating = filename.split('_')\n","            rating = int(rating.split(\".\")[0])\n","            data.append({'id': id, 'review': review, 'rating': rating, 'outcome': 0})\n","\n","df_neg = pd.DataFrame(data)\n","\n","directory = '/home/maxem/Downloads/aclImdb/test/neg'  # Replace with the actual directory path\n","\n","data = []\n","for filename in os.listdir(directory):\n","    if filename.endswith('.txt'):\n","        filepath = os.path.join(directory, filename)\n","        with open(filepath, 'r') as file:\n","            review = file.read()\n","            id, rating = filename.split('_')\n","            rating = int(rating.split(\".\")[0])\n","            data.append({'id': id, 'review': review, 'rating': rating, 'outcome': 0})\n","\n","df_neg_test = pd.DataFrame(data)\n","\n","directory = '/home/maxem/Downloads/aclImdb/test/pos'  # Replace with the actual directory path\n","\n","data = []\n","for filename in os.listdir(directory):\n","    if filename.endswith('.txt'):\n","        filepath = os.path.join(directory, filename)\n","        with open(filepath, 'r') as file:\n","            review = file.read()\n","            id, rating = filename.split('_')\n","            rating = int(rating.split(\".\")[0])\n","            data.append({'id': id, 'review': review, 'rating': rating, 'outcome': 0})\n","\n","df_pos_test = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>review</th>\n","      <th>rating</th>\n","      <th>outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1015</td>\n","      <td>I wait for each new episode, each re-run with ...</td>\n","      <td>7.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8851</td>\n","      <td>I have always been somewhat underwhelmed by Jo...</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7825</td>\n","      <td>It is to typical of people complaining about s...</td>\n","      <td>7.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2966</td>\n","      <td>No matter what you've heard, \"Fame\" is not a g...</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7198</td>\n","      <td>This is one of the films that killed the \"spag...</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>6460</td>\n","      <td>The reason why this movie isn't any better kno...</td>\n","      <td>5.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>11465</td>\n","      <td>Without a doubt, this is one of the worst pict...</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>566</td>\n","      <td>I loved the first 15 minutes, and I loved some...</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>10907</td>\n","      <td>Was flipping around the TV and HBO was showing...</td>\n","      <td>6.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>12330</td>\n","      <td>I can't describe the feeling when I got this c...</td>\n","      <td>5.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 4 columns</p>\n","</div>"],"text/plain":["          id                                             review  rating  \\\n","0       1015  I wait for each new episode, each re-run with ...     7.0   \n","1       8851  I have always been somewhat underwhelmed by Jo...     0.0   \n","2       7825  It is to typical of people complaining about s...     7.0   \n","3       2966  No matter what you've heard, \"Fame\" is not a g...     1.0   \n","4       7198  This is one of the films that killed the \"spag...     0.0   \n","...      ...                                                ...     ...   \n","49995   6460  The reason why this movie isn't any better kno...     5.0   \n","49996  11465  Without a doubt, this is one of the worst pict...     0.0   \n","49997    566  I loved the first 15 minutes, and I loved some...     2.0   \n","49998  10907  Was flipping around the TV and HBO was showing...     6.0   \n","49999  12330  I can't describe the feeling when I got this c...     5.0   \n","\n","       outcome  \n","0            1  \n","1            0  \n","2            0  \n","3            0  \n","4            0  \n","...        ...  \n","49995        0  \n","49996        0  \n","49997        0  \n","49998        1  \n","49999        0  \n","\n","[50000 rows x 4 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat([df_pos, df_neg, df_pos_test, df_neg_test], axis=0).sample(frac=1).reset_index(drop=True) ## shuffling, \"смешивание\" данных\n","df = df.astype({\"id\": str, \"review\": str, \"rating\": float})\n","df['rating'] = df['rating'].replace({1: 0, 2: 1, 3: 2, 4: 3, 7:4, 8:5, 9:6, 10:7})##Необходимое изменение, иначе CUDA выдаст ошибку (необходимо присутствие класса 0)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip3 install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.4.2 -q ## установка torch для rocm"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-04 14:29:33.368185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from datasets import load_dataset, Dataset, ClassLabel, Value, Features\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer ## использование очень удобной библиотеки Transformers "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T15:40:16.692562Z","iopub.status.busy":"2023-08-01T15:40:16.692126Z","iopub.status.idle":"2023-08-01T15:40:33.367372Z","shell.execute_reply":"2023-08-01T15:40:33.365936Z","shell.execute_reply.started":"2023-08-01T15:40:16.692500Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model_id = \"microsoft/deberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=8)\n","\n","def preprocess(dataset):\n","    return tokenizer(dataset[\"text\"], truncation=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T15:40:46.744784Z","iopub.status.busy":"2023-08-01T15:40:46.744391Z","iopub.status.idle":"2023-08-01T15:40:47.191429Z","shell.execute_reply":"2023-08-01T15:40:47.190441Z","shell.execute_reply.started":"2023-08-01T15:40:46.744752Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c7c77719e5f4a57916752c7b87cf54d","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = Dataset.from_pandas(df)\n","dataset = dataset.remove_columns([\"id\", \"outcome\"])\n","dataset = dataset.rename_column(\"review\", \"text\")\n","dataset = dataset.rename_column(\"rating\", \"label\")\n","tokenized_text = dataset.map(preprocess, batched=True)\n","tokenized_text_split = tokenized_text.train_test_split(test_size=0.2) ##Вместо распределения тренировочного\\тестировочного распределения данных 1\\1 было выбрано 1\\5\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c977920eaa884f6aa48d85da788cfd23","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 40000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 10000\n","    })\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import concatenate_datasets\n","imdb = load_dataset(\"imdb\") ## загрузка дополнительных данных, которые в итоге не были использованы\n","tokenized_imdb = imdb.map(preprocess, batched=True)\n","dataset_cc = concatenate_datasets([tokenized_imdb['train'], tokenized_imdb['train']])\n","tokenized_imdb_split = dataset_cc.train_test_split(test_size=0.2)\n","tokenized_imdb_split"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T15:41:26.603503Z","iopub.status.busy":"2023-08-01T15:41:26.603079Z","iopub.status.idle":"2023-08-01T15:41:26.623120Z","shell.execute_reply":"2023-08-01T15:41:26.621940Z","shell.execute_reply.started":"2023-08-01T15:41:26.603471Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"multi_class_classification_bert\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=2, ## датасет достаточно обширный, 2 эпох для этой модели оказалось достаточно\n","    eval_steps = 4000,\n","    save_steps = 4000,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"steps\",\n","    save_strategy=\"steps\",\n","    load_best_model_at_end=True,\n","    logging_steps = 50,\n","    report_to = \"wandb\", ## набор инструментов в основном для построения графиков прямо в процессе обучения (Weights and biases)\n","    save_total_limit=1,\n","    fp16 = False,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_text_split[\"train\"],\n","    eval_dataset=tokenized_text_split[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics = None ## если оставить None, то будет использоваться кросс-энтропия\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T15:41:49.450697Z","iopub.status.busy":"2023-08-01T15:41:49.449829Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbossprocool\u001b[0m (\u001b[33mmemers\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/maxem/Downloads/wandb/run-20230804_143022-rdssylc4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/memers/huggingface/runs/rdssylc4' target=\"_blank\">amber-leaf-136</a></strong> to <a href='https://wandb.ai/memers/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/memers/huggingface' target=\"_blank\">https://wandb.ai/memers/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/memers/huggingface/runs/rdssylc4' target=\"_blank\">https://wandb.ai/memers/huggingface/runs/rdssylc4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16fe2974cf794ef2aa39304addd32af0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/40000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1534\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1531\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1533\u001b[0m )\n\u001b[0;32m-> 1534\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1535\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1536\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1537\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1538\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1539\u001b[0m )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1807\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1806\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1807\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1809\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1810\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1811\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1812\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1813\u001b[0m ):\n\u001b[1;32m   1814\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1815\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2649\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2646\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2648\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2649\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2651\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2652\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2672\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2673\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2674\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2675\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2676\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2677\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:1211\u001b[0m, in \u001b[0;36mDebertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1211\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeberta(\n\u001b[1;32m   1212\u001b[0m     input_ids,\n\u001b[1;32m   1213\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1214\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1215\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1216\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1217\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1218\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1219\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1220\u001b[0m )\n\u001b[1;32m   1222\u001b[0m encoder_layer \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1223\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(encoder_layer)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:983\u001b[0m, in \u001b[0;36mDebertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    973\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    975\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    976\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    977\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    980\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m    981\u001b[0m )\n\u001b[0;32m--> 983\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    984\u001b[0m     embedding_output,\n\u001b[1;32m    985\u001b[0m     attention_mask,\n\u001b[1;32m    986\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    987\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    988\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    989\u001b[0m )\n\u001b[1;32m    990\u001b[0m encoded_layers \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m    992\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:476\u001b[0m, in \u001b[0;36mDebertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    467\u001b[0m     hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    468\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    469\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m         rel_embeddings,\n\u001b[1;32m    474\u001b[0m     )\n\u001b[1;32m    475\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    477\u001b[0m         next_kv,\n\u001b[1;32m    478\u001b[0m         attention_mask,\n\u001b[1;32m    479\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    480\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    481\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    482\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    483\u001b[0m     )\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    486\u001b[0m     hidden_states, att_m \u001b[39m=\u001b[39m hidden_states\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:383\u001b[0m, in \u001b[0;36mDebertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    375\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    376\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    382\u001b[0m ):\n\u001b[0;32m--> 383\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    384\u001b[0m         hidden_states,\n\u001b[1;32m    385\u001b[0m         attention_mask,\n\u001b[1;32m    386\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    387\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    388\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    389\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    390\u001b[0m     )\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    392\u001b[0m         attention_output, att_matrix \u001b[39m=\u001b[39m attention_output\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:316\u001b[0m, in \u001b[0;36mDebertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    308\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    309\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m     rel_embeddings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m ):\n\u001b[0;32m--> 316\u001b[0m     self_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    317\u001b[0m         hidden_states,\n\u001b[1;32m    318\u001b[0m         attention_mask,\n\u001b[1;32m    319\u001b[0m         output_attentions,\n\u001b[1;32m    320\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    321\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    322\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    325\u001b[0m         self_output, att_matrix \u001b[39m=\u001b[39m self_output\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:677\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    674\u001b[0m     attention_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_logits_proj(attention_scores\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    676\u001b[0m attention_probs \u001b[39m=\u001b[39m XSoftmax\u001b[39m.\u001b[39mapply(attention_scores, attention_mask, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 677\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(attention_probs)\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtalking_head:\n\u001b[1;32m    679\u001b[0m     attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_weights_proj(attention_probs\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:239\u001b[0m, in \u001b[0;36mStableDropout.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mCall the module\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m    x (`torch.tensor`): The input tensor to apply dropout\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_prob \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m XDropout\u001b[39m.\u001b[39;49mapply(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_context())\n\u001b[1;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m x\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T10:48:54.674738Z","iopub.status.busy":"2023-08-01T10:48:54.674336Z","iopub.status.idle":"2023-08-01T10:49:42.696889Z","shell.execute_reply":"2023-08-01T10:49:42.695836Z","shell.execute_reply.started":"2023-08-01T10:48:54.674705Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecd819a4e5274d208820bde6c6ade9d0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.2642443180084229, 'eval_runtime': 108.6392, 'eval_samples_per_second': 46.024, 'eval_steps_per_second': 11.506, 'epoch': 0.63}\n"]},{"data":{"text/plain":["{'eval_loss': 1.2642443180084229,\n"," 'eval_runtime': 108.6392,\n"," 'eval_samples_per_second': 46.024,\n"," 'eval_steps_per_second': 11.506,\n"," 'epoch': 0.63}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["trainer.save_model(\"tuned_multiclass_classification_actual\") ## удобно, что можно с помощью того же самого обьекта сохранить модель"]},{"cell_type":"markdown","metadata":{},"source":["Интересные мысль: изначальная идея решения была в том, чтобы задачу присвоения оценки (1-10) представить в качестве задачи регрессии. Но для последующих предсказаний натренированную модель оказалось достаточно непросто использовать (в то время как для этой это решается в пару строк кода), поэтому было принято решение так не делать. Также была тренирована модель для бинарной классификации (положительный\\отрицательный отзыв), но на сайте используется другой подход: оценка 1-4 - негативный отзыв, 7-10 - положительный (см. сайт). На дополнительной модели была достигнута функция потерь = 0.1"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
